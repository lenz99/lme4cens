---
title: "Censored observations in regression"
author: "MK"
date: "28 March 2017, `r Sys.Date()`"
output:
  ioslides_presentation:
    incremental: false
    widescreen: true
---



<!-- Latex stuff -->
\usepackage{amssymb}
\usepackage{amsmath}

\newcommand{\N}[1]{\mathcal{N}(#1)}
\newcommand{\R}{‚Ñù} 
\newcommand{\1}{ùüô}
\newcommand{\inv}{^{-1}}
<!-- matrix transpose {^\raisebox{.2ex}{\top}}}-->
\newcommand{\tr}{^\intercal}
\newcommand{\invtr}{^{\scriptscriptstyle-1!\intercal}}
\newcommand{\kron}{\:\otimes\:}
\newcommand{\yobs}{y_\text{obs}}

\DeclareMathOperator{\Cov}{Cov}
\DeclareMathOperator{\cov}{cov}
\DeclareMathOperator{\Var}{Var}
\DeclareMathOperator*{\argmin}{arg\,min}
\DeclareMathOperator{\logLik}{L}
\DeclareMathOperator{\rank}{rank}
\DeclareMathOperator{\TTr}{T}



```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
library(tibble)
library(dplyr)
library(survival)
library(microbenchmark)
library(censReg)
library(ggplot2)

library(devtools)
dev_mode(on = TRUE)
library(lme4cens)
```



## Motivation

<div class="columns-2">

- CML clinical trial
- molecular measurement of remission level
- patients are followed-up 
- bi-exponential form per patient assumed
- lower detection limit for individual measurements
- compare two treatments

```{r motivPlot, message=FALSE, fig.width=5, fig.height=6}
library(leukemiAnalysis)
pFit <- singlePatientFit(dat = 38, type = "lcensored")
plot(pFit, show.fit = FALSE, main = "Patient Follow-up Data")
detach("package:leukemiAnalysis")
```

</div>





# Censoring

## Censoring

> - A response $X$ is known to have occurred only within certain interval
> - Known from survival analysis
>     - Response: survival time, i.e. time to death
>     - Censoring: partially observed survival time, i.e. last seen alive
> - Right censoring: $X ‚àà [c_r, ‚àû)$
> - Left censoring: $X ‚àà (-‚àû, c_l]$
> - Types of censoring
>     - fixed right censoring time, e.g. study end ("Type I censoring")
>     - random (left or right) censoring



## Random censoring
<div class="columns-2">
- Two random variables
    - $X$ true response variable
    - $C_l$ censoring variable
- Example: random left censoring
<!-- - censoring: $X < C_l$ else $X ‚â• C_l$ -->
- Observable random vector (T, Œî)
    - $T=\max(X, C_l);$ Œî ‚àà {0,1} <!-- status -->
    - Œî=1 event: $$T = X \text{ and } X ‚â• C_l$$
    - Œî=0 censoring: $$T = C_l \text{ and } X < C_l$$
-


Function      |  Event X  | Censoring C~l~ |
------------  | --------- | ----------- |
Density       | f         |      g      |
Survival      | S         |      H      |
Cum Distrib   | F = 1 - S |     G = 1-H |
<!-- Hazard        | Œª         |        Œº    | -->

Table: Names for functions

</div>



## Likelihood Model
> - Assume distribution for $X$ with density f~Œ∏~ and parameter Œ∏
> - Given a random sample x=(x~1~, .., x~n~)
> - Generally: $$L(Œ∏\,|\, x) \propto \prod_{i=1}^n f_Œ∏(x_i)$$


## Density for (T, Œî)
> - Assume __independence__ for X and C
\[
\begin{aligned}
f_{(T, Œî)}(t, Œî = 1) &= f(t) \cdot (1-H(t))\\[1.5ex]
f_{(T, Œî)}(t, Œî = 0) &= g(t) \cdot (1-S(t))\\
\end{aligned}
\]
> - Together
\[
\begin{aligned}
f_{(T, Œî)}(t, Œ¥) &= (g(t) \cdot (1-S(t)))^{1-Œ¥} \cdot ( f(t) \cdot (1-H(t)) )^Œ¥\\
    &= \underbrace{f(t)^Œ¥ (1-S(t))^{1-Œ¥}}_{\text{response}} \cdot \underbrace{g(t)^{1-Œ¥} (1-H(t))^Œ¥}_{\text{censoring}}
\end{aligned}
\]


## Likelihood Model for Left-Censoring
> - Likelihood when event and censoring independent
\[
\begin{aligned}
L &= \prod_{i=1}^n f(t_i, Œ¥_i)\\
  &= \prod_{i=1}^n f(t_i)^{Œ¥_i} (1-S(t_i))^{1-Œ¥_i} \cdot g(t_i)^{1-Œ¥_i} (1-H(t_i))^{Œ¥_i}
\end{aligned}
\]
> - If censoring process __not__ of interest drop censoring terms:
\[
\begin{aligned}
L &\propto \prod_{i=1}^n f(t_i)^{Œ¥_i} (1-S(t_i))^{1-Œ¥_i}\\
  &= \prod_{i‚ààD} f(x_i) \cdot \prod_{i‚ààL} [1-S(x_i)]
\end{aligned}
\]

## Likelihood contributions

- For independent censoring:

Observed response    | Abbrev |  Contribution  | 
-----------------    | ------ | -------------- | 
exact                |  D  | f(x)           | 
right-censored       |  R  | S(x)           | 
left-censored        |  L  | 1-S(x)         | 
interval-censored    |  I  | S(L) - S(R)    |

$$
L \propto \prod_{i‚ààD} f(x_i) \cdot \prod_{i‚ààR} S(x_i) \cdot \prod_{i‚ààL} [1-S(x_i)] \cdot \prod_{i‚ààI} [ S(L_i) - S(R_i)]
$$


## Example {.example}
- Exponentially distributed response
- Random __right censoring__, independent of the response
- Sample {(t~1~, Œ¥~1~), ..., (t~n~, Œ¥~n~)} with $r$ observed events, i.e. |D|=r.
- Density $f(x) = Œª \cdot \exp(-Œª x)$ and survival $S(x) = \exp(-Œª x)$ with Œª > 0

> - Likelihood: $$L \propto \prod_{i‚ààD} f(x_i) \cdot \prod_{i‚ààR} S(x_i)$$
> - As function of parameter Œª:  $\; L(Œª) = Œª^r \cdot \exp(-Œª \sum_i t_i)$
> - Solution $\; \hat Œª = \frac{r}{\sum_i t_i}$




## Example {.example}
- Exponential distribution with parameter Œª > 0
- Random __left censoring__, independent of the response
$$
\begin{aligned}
L(Œª) &= \prod_{i‚ààD} f(x_i) \cdot \prod_{k‚ààL} [1-S(x_k)] \\
  &= Œª^r \cdot \exp(-Œª \sum_{i‚ààD} t_i) \cdot \prod_{k‚ààL} (1-\exp(-Œª t_k)) \\[1ex]
l(Œª) &= r \cdot \ln(Œª) - Œª \sum_{i‚ààD} t_i + \sum_{k‚ààL} \ln(1-\exp(-Œª t_k)) 
\end{aligned}
$$

- More complex form than with right censoring


## Example: own ML-implementation
```{r mle_exp_censLeft, echo = TRUE, eval = FALSE}
# neg. log-likelihood
negLogLik_expLCens <- function(data){
  
  nbrEvents <- sum(data$status)
  eventIdx <- data$status == 1L
  
  function(l)
    - nbrEvents * log(l) + l * sum(data$T[eventIdx]) -
    sum(log(1-exp(-l * data$T[!eventIdx])))
}

## find ML-estimate
optimize(negLogLik_expLCens(data), interval = c(0, 10))

```


## Implementation in R's `survival` package
- `survival::survreg` function for ML-fitting with censored observations
- Left-censoring
```{r survreg_left, echo=TRUE, eval=FALSE}
survreg(Surv(T, status, type = "left") ~ 1, dist = "exp", data)
```

- Right-censoring

```{r survreg_right, echo=TRUE, eval=FALSE}
survreg(Surv(T, status, type = "right") ~ 1, dist = "exp", data)
```



## Example: Tobit model {.example}
- Linear model with left-censored response ('latent' response)
- Tobin, Econometrica, 1958
$$
\begin{aligned}
y^* &= X Œ≤ + Œµ \qquad \text{ with } Œµ\sim \N{0, œÉ^2\cdot I_n} \\[1ex]
y_i   &= \Bigl\{ \begin{matrix} 0 & \text{ if } y_i^* ‚â§ 0 \\ 
                    y_i^* & \text{ if } y_i^* > 0 \end{matrix}
\end{aligned}
$$

> - Normal density $œï_{Œº, œÉ^2}$ and distribution function $F=Œ¶_{Œº, œÉ^2}$
> - Likelihood  $$L = \prod_{i‚ààD} œï_{x_i\tr Œ≤,œÉ^2}(y_i) \prod_{j‚ààL} Œ¶_{x_i\tr Œ≤,œÉ^2}(y_i)$$ 
<!-- $$L = \prod_{i‚ààD}\frac{1}{œÉ} œï(\frac{y_i - x_i\tr Œ≤}{œÉ}) \prod_{j‚ààL} Œ¶(\frac{y_i - x_i\tr Œ≤}{œÉ})$$ -->


## Example: implementation in `lme4cens` {.example}
- re-use `Surv`-object to model censoring in response
```{r lmcens, echo = TRUE}
lmcens(Surv(affairs, event, type = "left") ~ age + yearsmarried + occupation + rating,
       data = Affairs)
```






# Mixed models

## Example: `sleepstudy`

- Reaction time after continued sleep deprivation
- Repeated measurements per subject (subset of four subjects)

```{r sleepstudy2_plot1}
sleepstudy2 %>% 
  ggplot(data = ., mapping = aes(x = Days, y = Reaction)) +
  geom_point() + 
  facet_wrap(~Subject)
```


## Example: `sleepstudy` 

* Fit of random intercept model
	* common slope between individuals
	* individual intercept terms

```{r sleepstudy2_plot2, fig.width = 7, fig.height = 3.5}
fm <- lmer(Reaction ~ Days + (1|Subject), data = sleepstudy2)
sleepstudy2$pred <- predict(fm)

sleepstudy2 %>% 
  ggplot(data = ., mapping = aes(x = Days, y = Reaction)) +
  geom_point() + 
  geom_line(mapping = aes(x = Days, y = pred), colour = "orange", linetype = "dashed") + 
  facet_wrap(~Subject)

```


## The Linear Mixed Model
- Described by 2 vector-valued random variables
    - the response vector $Y$ _and_
    - the vector of random effects $B$
- conditional distribution of $Y$ given $B=b$
$$
Y_{\;|\; B = b} \sim \N{X\beta + Zb, \, \sigma^2 I_n}
$$

> - Conditionally on $B=b$, a simple diagonal covariance structure for $Y$
> - $Œ≤‚àà‚Ñù^p$ fixed effects
> - $b‚àà‚Ñù^q$ random effects
> - $Y$ is multivariate normal with complex covariance structure




## Random intercept model: matrices

* $B \sim \N{0, Œ£_Œ∏}$ where $Œ£_Œ∏$ is a $q\times q$-covariance matrix.
* Simple scalar random effect model

<div class="columns-2">

* Random effects design matrix

$$
Z =\Bigl[ \begin{smallmatrix} 1 & 0 & 0 & 0 \\ 1 & 0 & 0 & 0\\ 1 & 0 & 0 & 0\\ 1 & 0 &  0 & 0\\ 1 & 0 &  0 & 0\\ 1 & 0 &  0 & 0\\ 1 & 0 &  0 & 0\\ 1 & 0 &  0 & 0\\ 1 & 0 &  0 & 0\\ 1 & 0 &  0 & 0\\ 1 & 0 &  0 & 0\\
0 & 1 &  0 & 0 \\ 0 & 1 &  0 & 0 \\ \vdots & \vdots & \vdots & \vdots \end{smallmatrix}\Bigl]
‚àà ‚Ñù^{nêÑÇq}
$$

* Vector of random effects

$$
B = \Bigl[ \begin{smallmatrix} b_1 \\ b_2 \\ b_3 \\ b_4 \end{smallmatrix} \Bigl] \sim \N{0, œÉ_b^2 I_q} \\
   \; \text{ with between-subject variance } œÉ_b^2 \\
   \;
$$
</div>


<!-- $$ -->
<!-- \begin{aligned} -->
<!-- Z & =\Bigl[ \begin{smallmatrix} 1 & 0 & 0 & 0 \\ 1 & 0 & 0 & 0\\ 1 & 0 & 0 & 0\\ 1 & 0 &  0 & 0\\ 1 & 0 &  0 & 0\\ 1 & 0 &  0 & 0\\ 1 & 0 &  0 & 0\\ 1 & 0 &  0 & 0\\ 1 & 0 &  0 & 0\\ 1 & 0 &  0 & 0\\ 1 & 0 &  0 & 0\\ -->
<!-- 0 & 1 &  0 & 0 \\ 0 & 1 &  0 & 0 \\ \vdots & \vdots & \vdots & \vdots \end{smallmatrix}\Bigl] -->
<!-- ‚àà ‚Ñù^{nêÑÇq}\\ -->
<!-- B & = \Bigl[ \begin{smallmatrix} b_1 \\ b_2 \\ b_3 \\ b_4 \end{smallmatrix} \Bigl] \sim \N{0, œÉ_b^2 I_q} \\ -->
<!--   & \; \text{ with between-subject variance } œÉ_b^2 \\ -->
<!--   & \; -->
<!-- \end{aligned} -->
<!-- $$ -->


## Random effects
> - $Œ£_Œ∏ = œÉ^2 Œõ_Œ∏ Œõ_Œ∏^T$ Cholesky-decomposition
>     * variance-component parameter Œ∏ _and_
>     * __relative covariance factor__ $Œõ_Œ∏ ‚àà ‚Ñù^{q\times q}$
> - Use __spherical random-effects__ variable $U \sim \N{0, \sigma^2 I_q}$ with $$B = Œõ_Œ∏ U$$


## Random intercept model: formulae

> * $Œ£_Œ∏ = œÉ_b^2 I_q = œÉ^2 Œõ_Œ∏ Œõ_Œ∏^T$
> * $Œõ_Œ∏ = \frac{œÉ_b}{œÉ} I_q$ 
> * $U = \frac{œÉ}{œÉ_b} \cdot B$
> * $Y|_{U = u} \sim \N{XŒ≤ + Z \frac{œÉ_b}{œÉ} u, \, \sigma^2 I_n}$







## Densities
* Y|U and U are multivariate normal variables
* Residual sum of squares $\rho^2(\theta, \beta, u) := \big\| y_\text{obs} - \mu_{Y | U=u} \big\|^2$

$$
\begin{aligned}
f_{Y|U}(\yobs | u)   &=   \frac{1}{(2\pi \sigma^2)^{n/2}} \cdot \exp \frac{-\rho^2(\theta, \beta, u)}{2\sigma^2}\\
f_U (u)    &= \frac{1}{(2\pi\sigma^2)^{q/2}} \cdot \exp \frac{- \|u\|^2}{2\sigma^2} \\[3.25ex]
f_{Y,U}(\yobs, u)    &=   f_{Y|U}(\yobs | u)  \quad \cdot \quad f_U (u)
\end{aligned}
$$


## Joint density
$$
\begin{aligned}
f_{Y,U}(\yobs, u)    &=   f_{Y|U}(\yobs | u)  \qquad \cdot \qquad f_U (u) \\
    & = \frac{1}{(2\pi \sigma^2)^{n/2}} \exp \frac{-\rho^2(\theta, \beta, u)}{2\sigma^2} \; \cdot \; \frac{1}{(2\pi\sigma^2)^{q/2}} \exp \frac{- \|u\|^2}{2\sigma^2} \\
    & =  \frac{1}{(2\pi \sigma^2)^{(n+q)/2}} \cdot \exp \frac{-\rho^2(\theta, \beta, u) - \|u\|^2 }{2\sigma^2}\\
    & =  \frac{1}{(2\pi \sigma^2)^{(n+q)/2}} \cdot \exp \frac{-r^2(\theta, \beta, u) }{2\sigma^2}
\end{aligned}
$$

* __penalized residual sum-of-squares__ $r^2(\theta, \beta, u) := \rho^2(\theta, \beta, u) + \|u\|^2$ 



## Likelihood
$$
\begin{aligned}
L(\theta, \beta, \sigma^2 | \yobs) &=  f_Y(\yobs) \\
    &= \int f_{Y,U}(\yobs, u) du \\
    &=  \int f_{Y|U}(\yobs | u) \cdot f_U(u) du\\
  %%&=  \int \frac{\sqrt{|W|}}{(2\pi \sigma^2)^{n/2}} \exp \frac{-\rho^2(\theta, \beta, u)}{2\sigma^2} \cdot \frac{1}{(2\pi \sigma^2)^{q/2}} \exp \frac{-\|u\|^2}{2\sigma^2} du \\
  &=  \frac{1}{(2\pi \sigma^2)^{(n+q)/2}} \cdot \int \exp \frac{-r^2(\theta, \beta, u)}{2\sigma^2} du
\end{aligned}
$$






## Likelihood for random intercept model

- Contribution for subject $i$

$$
\begin{aligned}
L_i(\theta, \beta, \sigma^2 | y_i) &=  f_Y(y_i) = \int f_{Y,U}(y_i, u_i) \, du_i \\
    &= \int f_{Y|U}(y_i | u_i) \cdot f_U(u_i) \, du_i\\
    &= \int œï_{X_i Œ≤ + \frac{œÉ_b}{œÉ}u_i, œÉ^2}(y_i)\cdot  œï_{0, œÉ^2} (u_i) \, du_i\\
    &= \int œï_{X_i Œ≤ + b_i, œÉ^2}(y_i) \cdot  œï_{0, œÉ_b^2} (b_i) \, db_i\\
\end{aligned}
$$

- Together __not__ a product of likelihood contribution of individual observations
- __Penalized least squares (PLS)__  problem


# Efficient Estimation of Linear Mixed Models 

## Pseudo-data approach {.incremental}
* Amend the observed data $y_\text{obs}$ with an "observed" $u_\text{obs}=0$ for the (unobservable) spherical
random-effects variable $u$
* PLS-problem becomes a standard least square problem in the amended space

$$
\begin{aligned}
r^2(\theta, \beta, u)  &= \Big\| \begin{bmatrix}  \yobs - \mu_{Y | U=u} \\  -u \end{bmatrix} \Big\|^2 \\
 &= \Big\| \underbrace{\begin{bmatrix}  \yobs  \\ 0\end{bmatrix}}_{ =: \tilde y}  - 
\underbrace{\begin{bmatrix}  Z \Lambda_\theta &  X \\ I_q & 0\end{bmatrix}}_{ =: \tilde X_Œ∏} \begin{bmatrix} u \\ \beta \end{bmatrix} \Big\|^2
\end{aligned}
$$

* Find optimal parameters $\hat \mu_{U|Y=y_\text{obs}}, \hat \beta_\theta$ (via normal equation) as function of Œ∏
<!-- * Allows to profile out parameters $\beta$ and $\mu_{U|Y=y_\text{obs}}$ as a function of Œ∏ -->
* Define $\mathbf{r^2(\theta)} := r^2(\theta, \hat \beta_\theta, \hat \mu_{U|Y=y_\text{obs}})$



## Maximum Likelihood Estimation

* Parameterized by Œ∏ only (Œ≤ and œÉ profiled out) 

$$
\begin{aligned}
\log L (\theta | y_{\text{obs}}) &= \log |L_\theta |\inv - \frac{n}{2} \cdot \big[ 1 + \log \frac{2 \pi \cdot r^2(\theta)}{n} \big]\\[.5ex]
  &\; (L_Œ∏ \text{ is a matrix derived from } \tilde X_Œ∏)
\end{aligned}
$$

* Use general optimizer to maximize $Œ∏ \mapsto L(Œ∏)$
* Repeated evaluation of PLS-algorithm





# Mixed models with Censoring

## Example: sleepstudy
- Subset of `sleepstudy`-data with left- and right-censoring

```{r sleepstudy2_plot}
sleepstudy2 %>% 
  dplyr::mutate_(shapeCol = ~factor(event3, levels = 0:2, labels = c("right", "obs", "left"))) %>% 
  ggplot(data = ., mapping = aes(x = Days, y = Reaction,
             colour = shapeCol, shape = shapeCol)) + 
  geom_point() + 
  facet_wrap(~Subject) + 
  scale_shape_manual(values = c(right = 17, obs = 16, left = 25), guide = guide_legend(title = "Status")) + 
  guides(colour = FALSE)
```



## Likelihood w/ left censoring

- Contribution for subject $i$

$$
\begin{aligned}
L_i(\theta, \beta, \sigma^2 | y_i) &=  f_Y(y_i) \\
    &= \int f_{Y,U}(y_i, u_i) du_i \\
    &=  \int f_{Y|U}(y_i | u_i) \cdot f_U(u_i) du_i \\
    &= \int \bigl[ \prod_{t‚ààD} œï_{x_{it}\tr Œ≤ + b_i, œÉ^2}(y_{it}) \prod_{k‚ààL} Œ¶_{x_{ik}\tr Œ≤ + b_i, œÉ^2}(y_{ik})  \bigr] \cdot œï_{0, œÉ_b^2}(b_i)  db_i\\
    %% &= \int \bigl[ \prod_{t‚ààD} \frac{1}{œÉ} \cdot œï(\frac{y_{it} - x_{it}\tr Œ≤ - b}{œÉ})  \prod_{k‚ààL} Œ¶(\frac{y_{ik} - x_{ik}\tr Œ≤ - b}{œÉ})  \bigr] \cdot \frac{1}{œÉ_b} œï(\frac{b}{œÉ_b})  db \\ 
\end{aligned}
$$


## Gau√ü-Hermite quadrature

- Evaluate an improper integral as weighted average of order o
- Fewer function evaluations than standard numerical integration

$$
\int_{-\infty}^\infty \exp(-x^2) \;f(x) \, dx \approx \sum_{i=1}^o w_i \cdot f(x_i)
$$

```{r gh_int_benchmark}
readRDS("benchm_ghInt_rInt.rds")
```





## Implementation in `lme4cens`

- Random intercept model
- Re-use modules from `lme4`

```{r sleepstudy_lmeCens, echo=TRUE}
lmercens(Surv(Reaction, time2 = Reaction, event = event2, type = "interval") ~ 
  Days + (1|Subject), data = sleepstudy2, REML = FALSE)
```


## Outlook

```{r ex2_sleepstudy2_censReg, eval = FALSE}
sleepstudy2 %>% 
  dplyr::mutate_(Reaction = ~ pmin(pmax(Reaction, 212), 350))  %>% 
  plm::pdata.frame(index = c("Subject", "Days")) %>% 
  censReg(Reaction ~ as.numeric(Days), left = 212, right = 350, start = paramS, data = .) ->
  
  fm_sleepstudy2_censReg

fm_sleepstudy2_censReg
```


- Validate results:
    - simulation studies
    - package `censReg` implements random-intercept censored regression in R
- Implement also restricted maximum likelihood (REML)
- Implement non-linear mixed models with censoring
- Tap deeper into `lme4`-structures 
- Allow for more complex random-effect structures
    - Other fitting methods: _maximum simulated likelihood_


----- 

~ Fine ~





# Backup slides

## Likelihood Model for Left-Censoring
- Censoring $C_l$
\[
\begin{aligned}
P(t ‚â§ T ‚â§ t + h, Œ¥ = 0) &= P(t ‚â§ C_l ‚â§ t + h, C_l ‚â• X)\\
    &\approx P(t ‚â§ C_l ‚â§ t + h, t ‚â• X)\\
    &= P(t ‚â§ C_l ‚â§ t + h) \cdot P(X ‚â§ t)\\
    &= g(Œæ) h \cdot (1-S(t)) \qquad \text{ a  Œæ ‚àà [t, t+h)}\\[1ex]
\end{aligned}
\]
- Observed response $X$
\[
\begin{aligned}
P(t ‚â§ T ‚â§ t + h, Œ¥ = 1) &= P(t ‚â§ X ‚â§ t + h, C_l ‚â§ X)\\
    &\approx P(t ‚â§ X ‚â§ t + h, C_l ‚â§ t)\\
    &= P(t ‚â§ X ‚â§ t + h) \cdot P(C_l ‚â§ t)\\
    &= f(Œæ) h \cdot (1-H(t)) \qquad \text{ a  Œæ ‚àà [t, t+h)}
\end{aligned}
\]


 


