---
title: "Linear Models with Censoring Examples"
author: "Matthias Kuhn"
date: "2017-02-27, last update: `r Sys.Date()`"
output:
  rmarkdown::html_vignette:
    toc: true
    fig_caption: yes
vignette: >
  %\VignetteIndexEntry{Linear Models with Censoring Examples}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include=FALSE, message=FALSE}
library('dplyr')

## knitr package options
knitr::opts_knit$set(verbose = FALSE)
options(digits = 3L)

library('survival')

library('lme4cens')
library('microbenchmark')

library('censReg')
library('crch')

data("Affairs", package = "lme4cens")

VERBOSE <- 0L
```

We demonstrate examples for linear regression analysis for censored observations.



## Exponential distribution
We model an event process $X$ and a censoring process $C$.
With right-censoring you actually observe only the earlier (min) of the two processes, while with left-censoring the later (max) of the two processes.
We generate random data for both, event and censoring independent of each other from a Weibull distribution.

```{r expLeftCens_data}
set.seed(123L)
N <- 230L
λ <- 1.8

ex_exp_lCens <- dplyr::tibble(
  X = rweibull(n = N, shape = 1L, scale = 1/λ),
  # censoring with shorter mean time than for response X
  Cl = rweibull(n = N, shape = 1.2, scale = 1/λ-.3), 
  T = pmax(X, Cl),
  status = as.numeric(X >= Cl)
)
```


The left-censoring does not allow for an easy analytic solution. Hence, we do an own numeric likelihood maximization.
We use a factory function `negLogLik` that --given a data sample-- produces a negative likelihood function.
`optimize` is R's standard function for optimization of one parameter only.

```{r expLeftCens_logLik}

# factory method for negative log-likelihood function
# function log1mexp efficiently calculates log(1-exp(x))
negLogLik <- function(data){
  stopifnot( is.data.frame(data),
             all(c("T", "status") %in% names(data)) )
  
  nbrEvents <- sum(data$status)
  eventIdx <- data$status == 1L
  
  function(λ)
    - nbrEvents * log(λ) + λ * sum(data$T[eventIdx]) - sum(lme4cens::log1mexp(-λ * data$T[!eventIdx]))
}


optimize(negLogLik(data = ex_exp_lCens), interval = c(0, 10))
```

The same result can be achieved via `survival::survreg`:

```{r expLeftCens_survreg}
fm.exp <- survreg(Surv(T, status, type = "left") ~ 1, dist = "exp",
        data = ex_exp_lCens)
fm.exp
```


`survreg`'s linear predictor η is transformed to our λ via 1/exp(η),
i.e. λ = 1/ exp(`r coef(fm.exp)`) = `r exp(-coef(fm.exp))`.







## Tobit-model: linear regression with censored observations

Tobit model assumes normal error distribution around the mean that is described by an equation that is linearly parameterized. 

In order to compare our fits with fits from other packages we use a fixed censoring value for all observations.
Here we use the `Affairs`-data as an example with left-censored response.
The response is self-reported _number of affairs_ in the previous year and is a non-negative integer.
In order to use linear regression we treat values 0 as left-censored
(i.e. we allow to model a response with also negative values but we do not observe these negative values).
Different characteristics of the person and its marriage serve as predictors.

We have prepared a column `event` that encodes for the left-censoring at 0:
```{r affairs_event_boxplot}
boxplot(affairs ~ event, data = Affairs, xlab = "Variable 'event'", ylab = "Number of affairs")
```


### Simple regression
We start with a single predictor `yearsmarried`. We use default BFGS and Nelder-Mead with gradient.

#### Nelder-Mead
```{r affairs_simple_lmcens_NM}
fm.aff.simple <- lmcens(Surv(affairs, event, type = "left") ~ yearsmarried, data = Affairs,
                        method = "Nelder")
summary(fm.aff.simple)
```

#### BFGS
```{r affairs_simple_lmcens_BFGS}
fm.aff.simple.bfgs <- lmcens(Surv(affairs, event, type = "left") ~ yearsmarried,
                             method = "BFGS",
                             data = Affairs)
summary(fm.aff.simple.bfgs)
```

#### censReg
We compare the output with the fit from `censReg`.
```{r affairs_simple_censReg, echo = FALSE}
fm.aff.simple.censreg <- censReg(affairs ~ yearsmarried, left = 0L, data = Affairs)

summary(fm.aff.simple.censreg)
```

The results of both model fitting routines do agree.


#### `survreg`
Parametric regression is supported in `survival::survreg` function, also known as accelerated failure time (AFT) models.
It allows for different error distributions. We choose `'gaussian'` to specify the same model as before:

```{r affairs_simple_survreg, echo = FALSE}
fm.aff.simple.censreg <- survreg(Surv(affairs, event, type = "left") ~ yearsmarried,
                                 dist = "gaussian", data = Affairs)
summary(fm.aff.simple.censreg)
```





### Multiple regression

Now, we consider more than one regression variable.

#### Nelder-Mead
If we use Nelder-Mead (NM) optimization we get this fit:
```{r affairs_multiple_lmcens}
fm.aff <- lmcens(Surv(affairs, event, type = "left") ~ age + yearsmarried + religiousness + occupation + rating,
                 method = "Nelder", data = Affairs)

summary(fm.aff)
```

NM does not use the gradient information and therefore easily gets stuck in a local maximum of the log-likelihood funciton.

#### BFGS method
Now, we use `lmcens`'s standard optimization method `BFGS` as optimization method.

```{r affairs_multiple_lmcens_bfgs}
fm.aff.bfgs <- lmcens(Surv(affairs, event, type = "left") ~ age + yearsmarried + religiousness + occupation + rating,
                       ##start = c(coef(lm(affairs ~ age + yearsmarried + religiousness + occupation + rating, data = Affairs)), 2),
                      method = "BFGS",
                      data = Affairs)

summary(fm.aff.bfgs)
```


#### Effect of bad start values

When we use the BFGS-optimization method with rough start values (all zeros) we get no convergence at a good model fit:

```{r affairs_multiple_lmcens_bfgs_badStart}
fm.aff.bfgs.badstart <- lmcens(Surv(affairs, event, type = "left") ~ age + yearsmarried + religiousness + occupation + rating,
                      start = rep(0, 7L),
                      method = "BFGS",
                      data = Affairs)

summary(fm.aff.bfgs.badstart)
```

The fit is erroneous!!
We get very different coefficients to the previous fit and the log-likelihood is clearly worse.
So, good start values do matter for bigger models (with possibly correlated predictors).




#### Multiple Tobit model with `censReg`

We compare our results with the output of `censReg`.

```{r affairs_multiple_censReg__NelderMead}
fm.aff.censreg <- censReg(affairs ~ age + yearsmarried + religiousness + occupation + rating, 
                          left = 0L,
                          data = Affairs)

summary(fm.aff.censreg)
```

The coefficients are very close to those of our `BFGS`-fit!!




#### Double checks

We compare likelihood contributions at different parameter values

##### lmcens-NM 
We look into the log-likelihood contributions per observations of the final Nelder-Mead fit after auto-start,
once in our implementation and then via `censReg` implementation.
The contriubtions really coincide.

```{r ex1_compare_logLiks, fig.width=6, fig.height=6}
llContribs <- attr(fm.aff$logLik.contribs, "loglik.contribs")
llContribs.censreg <- update(fm.aff.censreg, start = coef(fm.aff), logLikOnly = TRUE)

MASS::eqscplot(x = llContribs, y = llContribs.censreg, pch = 16, cex = 0.75); abline(0,1, col = "grey", lty = 2)
```

The log-likelihood for the optimal fit from `lmcens` is calculated by `censReg` as `r sum(llContribs.censreg)`.


##### NM with good start values from `censReg`
When we start our `lmcens` with the parameter estimates of `censReg` (rounded on 1 digit) using Nelder-Mead we stay in that optimum region and get very similar results than what `censReg` delivers:
```{r ex1_lmcens_affairs_censRegStart}
fm.aff2 <- lmcens(Surv(affairs, event, type = "left") ~ age + yearsmarried + religiousness + occupation + rating,
                  start = round(coef(fm.aff.censreg),3),
                  method = "Nelder",
                  data = Affairs)

summary(fm.aff2)
```
So, Nelder-Mead is OK even for multiple regression as long as you have good start values, close enough to optimal values.

##### lmcens-NM after `censReg`-start values
We plot the log-likelihood contributions from fitted `lmcens`-model with Nelder-Mead 
with start parameters coming from `censReg`-fit
and also calculate these contributions via the `censReg`-package.

```{r ex1_compare_logLiks2, fig.width=7, fig.height=7}
llContribs2 <- attr(fm.aff2$logLik.contribs, "loglik.contribs")
llContribs2.censreg <- update(fm.aff.censreg, start = coef(fm.aff2), logLikOnly = TRUE)

MASS::eqscplot(x = llContribs2, y = llContribs2.censreg); abline(0,1, col = "grey", lty = 2)
```
We see also a good agreement of the differently calculated log-likelihood contributions.



#### Tobit Model with `crch`

```{r ex1_crch_affairs}

fm.aff.crch <- crch(affairs ~ age + yearsmarried + religiousness + occupation + rating,
                    data = Affairs, left = 0, dist = "gaussian")
summary(fm.aff.crch)
```

The package `crch` also coincides with the default fit from `censReg`.



#### `survreg`
We use parametric AFT-models from `survival`-package. Specifying a Gaussian error distribution within `survreg` should yield the same model.

```{r affairs_survreg, echo = FALSE}
fm.aff.censreg <- survreg(Surv(affairs, event, type = "left") ~ age + yearsmarried + religiousness + occupation + rating, dist = "gaussian", data = Affairs)
summary(fm.aff.censreg)
```





### Multiple regression with weights

We explicitly give higher weight to cases with positive religiousness _and_ positive number of affairs.
The resulting coefficient for `religiousness` changes from significantly negative towards 0 accordingly.


#### lmcens with NM
```{r affairs_lmcens_w}
wPos <- with(Affairs, which(affairs > 1 & religiousness > 2))
w <- rep(1L, NROW(Affairs))
w[wPos] <- 2.5


fm.aff.w.nm <- lmcens(Surv(affairs, event, type = "left") ~ age + yearsmarried + religiousness + occupation + rating,
              weights = w, method = "Nelder", data = Affairs)
summary(fm.aff.w.nm)
```


#### lmcens with BFGS
We check the results from `BFGS`-fitting:
```{r affairs_lmcens_w_bfgs}

fm.aff.w.bfgs <- lmcens(Surv(affairs, event, type = "left") ~ age + yearsmarried + religiousness + occupation + rating,
                        method = "BFGS",
                        weights = w, data = Affairs)
summary(fm.aff.w.bfgs)
```
BFGS comes to a fit with better log-likelihood. 


#### survreg
```{r affairs_survreg_w, echo = FALSE}
fm.aff.w.survreg <- survreg(Surv(affairs, event, type = "left") ~ age + yearsmarried + religiousness + occupation + rating,
                        dist = "gaussian",
                        weights = w, data = Affairs)
summary(fm.aff.w.survreg)
```

The estimates for coefficients are virtually the same with our `BFGS`-fit.
But standard errors and log-likelihood value differ between the two implementations.

